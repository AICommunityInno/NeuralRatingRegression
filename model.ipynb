{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: CUDA_VISIBLE_DEVICES=2\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "from torch.autograd import Variable\n",
    "from itertools import chain\n",
    "\n",
    "from data_reader import amazon_dataset_iters\n",
    "from tqdm import tqdm\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import gc\n",
    "%matplotlib inline\n",
    "%env CUDA_VISIBLE_DEVICES=2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "if torch.cuda.is_available():\n",
    "    import torch.cuda as device\n",
    "else:\n",
    "    import torch as device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#TODO: set constants to ones from constants.py\n",
    "class Merger(nn.Module):\n",
    "    def __init__(self, latent_factors_count, hidden_size):\n",
    "        super(Merger, self).__init__()\n",
    "        self.user_model = nn.Linear(latent_factors_count, hidden_size, bias=False)\n",
    "        self.item_model = nn.Linear(latent_factors_count, hidden_size, bias=False)\n",
    "        self.bias = nn.Parameter(torch.Tensor(1))\n",
    "        \n",
    "    def forward(self, user_embed, item_embed):\n",
    "        return nn.Sigmoid()(self.user_model(user_embed) + self.item_model(item_embed) + self.bias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class ContextMerger(nn.Module):\n",
    "    def __init__(self, latent_factors_count, vocabulary_size, context_size):\n",
    "        super(ContextMerger, self).__init__()\n",
    "        self.user_model = nn.Linear(latent_factors_count, context_size, bias=False)\n",
    "        self.item_model = nn.Linear(latent_factors_count, context_size, bias=False)\n",
    "        self.rating_weight = nn.Parameter(torch.Tensor(1))\n",
    "        self.review_model = nn.Linear(vocabulary_size, context_size, bias=False)\n",
    "        self.bias = nn.Parameter(torch.Tensor(1))\n",
    "        \n",
    "    def forward(self, user_embed, item_embed, rating, review):\n",
    "        return nn.Tanh()(\n",
    "            self.user_model(user_embed) + self.item_model(item_embed) + \\\n",
    "            self.rating_weight * rating + self.review_model(review) + self.bias\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class EncoderModel(nn.Module):\n",
    "    def __init__(self, users_count, items_count, latent_factors_count, vocabulary_size=333,\n",
    "                 context_size=50, hidden_size=400, n_regression_layers=3, n_review_layers=1):\n",
    "        super(EncoderModel, self).__init__()\n",
    "        self.latent_factors_count = latent_factors_count\n",
    "\n",
    "        self.user_embedding = nn.Embedding(users_count, latent_factors_count)\n",
    "        self.item_embedding = nn.Embedding(items_count, latent_factors_count)\n",
    "        \n",
    "        self.merger = Merger(latent_factors_count, hidden_size)\n",
    "        self.regression_model = nn.Sequential(\n",
    "              *(list(chain.from_iterable([\n",
    "                  [nn.Linear(hidden_size, hidden_size), nn.Sigmoid()]\n",
    "                  for _ in range(n_regression_layers - 1)])) + \\\n",
    "              [nn.Linear(hidden_size, hidden_size), nn.Linear(hidden_size, 1)])\n",
    "        )\n",
    "        self.review_model = nn.Sequential(\n",
    "            *(list(chain.from_iterable([\n",
    "                      [nn.Linear(hidden_size, hidden_size), nn.Sigmoid()]\n",
    "                      for _ in range(n_review_layers - 1)])) + \\\n",
    "                  [nn.Linear(hidden_size, vocabulary_size)])\n",
    "        )\n",
    "        self.context_merger = ContextMerger(latent_factors_count, vocabulary_size, context_size)\n",
    "\n",
    "    def forward(self, input_user, input_item):\n",
    "        embedded_user = self.user_embedding(input_user)\n",
    "        embedded_item = self.item_embedding(input_item)\n",
    "        \n",
    "        merged = self.merger(embedded_user, embedded_item)\n",
    "        regression_result = self.regression_model(merged)\n",
    "        review_result = self.review_model(merged)\n",
    "        review_softmax = nn.LogSoftmax()(review_result)\n",
    "        \n",
    "        context = self.context_merger(embedded_user, embedded_item, regression_result, review_result)\n",
    "        return regression_result, review_softmax, context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class DecoderModel(nn.Module):\n",
    "    def __init__(self, hidden_size=400, context_size=50, vocabulary_size=333):\n",
    "        super(DecoderModel, self).__init__()\n",
    "        \n",
    "        self.embedding = nn.Embedding(vocabulary_size, context_size)\n",
    "        self.gru = nn.GRU(context_size, context_size)\n",
    "        self.out = nn.Linear(context_size, vocabulary_size)\n",
    "        self.softmax = nn.LogSoftmax()\n",
    "        \n",
    "    def forward(self, output, hidden):\n",
    "        output = torch.transpose(self.embedding(output), dim1=0, dim2=1)\n",
    "        hidden = hidden.view(1, hidden.size()[0], -1)\n",
    "        output, hidden = self.gru(output, hidden)\n",
    "        output = F.log_softmax(torch.transpose(self.out(output), dim1=2, dim2=0))\n",
    "        output = torch.transpose(output, dim1=0, dim2=1)\n",
    "        output = torch.transpose(output, dim1=1, dim2=2)\n",
    "        return output, hidden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "    \n",
    "    def __init__(self, users_count=192403, # defaults are for Electronics Dataset\n",
    "                 items_count=63001,\n",
    "                 latent_factors_count=300,\n",
    "                 vocabulary_size=70294,\n",
    "                 context_size=400,\n",
    "                 hidden_size=400,\n",
    "                 max_tip_len=22):\n",
    "        super(Model, self).__init__()\n",
    "        self.SEQ_START_ID = 2 # TODO accept vocabulary take ID from it\n",
    "        self.encoder = EncoderModel(users_count=users_count,\n",
    "                                    items_count=items_count,\n",
    "                                    latent_factors_count=latent_factors_count,\n",
    "                                    vocabulary_size=vocabulary_size,\n",
    "                                    context_size=context_size,\n",
    "                                    hidden_size=hidden_size)\n",
    "        \n",
    "        self.decoder = DecoderModel(hidden_size=hidden_size,\n",
    "                                    context_size=context_size,\n",
    "                                    vocabulary_size=vocabulary_size)\n",
    "        \n",
    "        self.max_tip_len = max_tip_len\n",
    "        self.empty_output = [[self.SEQ_START_ID] * self.max_tip_len]\n",
    "        self.vocabulary_size = vocabulary_size\n",
    "        \n",
    "    def forward(self, input_user, input_item):\n",
    "        regression_result, review_softmax, context = self.encoder.forward(input_user, input_item)\n",
    "        output_tip_probs = Variable(device.LongTensor(self.empty_output * len(input_user))) \n",
    "        output, hidden = self.decoder.forward(output_tip_probs, context)\n",
    "        return regression_result, review_softmax, output\n",
    "    \n",
    "    def voc_size(self):\n",
    "        return self.vocabulary_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def review_loss(c_hat, c):\n",
    "    assert c_hat.size() == c.size(), '{} != {}'.format(c_hat.size(), c.size()) \n",
    "    return torch.mul(c_hat, c.float()).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Trainer(object):\n",
    "    \n",
    "    def __init__(self, model):\n",
    "        self.model = model\n",
    "        \n",
    "        self.loss_criterion = (\n",
    "            lambda r, r_hat, c, c_hat, s, s_hat:\n",
    "                nn.MSELoss()(r_hat, r) + review_loss(c_hat, c) + nn.NLLLoss()(s_hat, s)\n",
    "        )\n",
    "        self.optimizer = optim.Adadelta(model.parameters(),\n",
    "                                        weight_decay=0.0001) # L2 regularisation is included here\n",
    "    \n",
    "    def train(self, train_iter, n_epochs=10): # TODO change n_epochs to 1000\n",
    "        losses = []\n",
    "        \n",
    "        for epoch_i in range(n_epochs):\n",
    "            for batch in tqdm(train_iter, desc=\"epoch %d / %d\" % (epoch_i, n_epochs)):\n",
    "                # TODO extract info from the batch\n",
    "                users_batch = batch.user\n",
    "                items_batch = batch.item\n",
    "                ratings_batch = batch.rating\n",
    "                reviews_batch = batch.text\n",
    "                tips_batch = torch.transpose(batch.tips, dim1=0, dim2=1)\n",
    "\n",
    "                regression_result, review_softmax, tips_output = self.model.forward(users_batch, items_batch)\n",
    "                self.optimizer.zero_grad()\n",
    "                \n",
    "                loss = self.loss_criterion(ratings_batch, regression_result,\n",
    "                                           reviews_batch, review_softmax,\n",
    "                                           tips_batch.contiguous().view(-1),\n",
    "                                           tips_output.contiguous().view(-1, model.voc_size()))\n",
    "                losses.append(loss.data.cpu().numpy())\n",
    "\n",
    "                loss.backward()\n",
    "                self.optimizer.step()\n",
    "                gc.collect()\n",
    "                # TODO print statistics from training / validation\n",
    "        return losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading datasets...\n",
      "datasets loaded\n",
      "item vocab built\n",
      "user vocab built\n",
      "text vocab built\n",
      "tips vocab built\n"
     ]
    }
   ],
   "source": [
    "text_vocab, tips_vocab, train_iter, val_iter, test_iter = (\n",
    "    amazon_dataset_iters('./data/reviews_Movies_and_TV_5/')\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "117340"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(text_vocab.itos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# with device.device(0):\n",
    "model = Model(vocabulary_size=len(text_vocab.itos),\n",
    "              items_count=50052,\n",
    "              users_count=123960, context_size=50, hidden_size=50).cuda()\n",
    "trainer = Trainer(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 0 / 20:   0%|          | 42/42439 [15:36<262:33:06, 22.29s/it]"
     ]
    }
   ],
   "source": [
    "# test_iter.train = True\n",
    "history = trainer.train(train_iter, n_epochs=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(-np.array(history))\n",
    "plt.yscale('log')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stuff for testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading datasets...\n",
      "datasets loaded\n",
      "item vocab built\n",
      "user vocab built\n",
      "text vocab built\n",
      "tips vocab built\n"
     ]
    }
   ],
   "source": [
    "small_text_vocab, small_tips_vocab, small_train_iter, small_val_iter, small_test_iter = (\n",
    "    amazon_dataset_iters('./data/sample_dataset/')\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# with device.device(0):\n",
    "model = Model(vocabulary_size=len(small_text_vocab.itos),\n",
    "              items_count=50052,\n",
    "              users_count=123960, context_size=50, hidden_size=50).cuda()\n",
    "trainer = Trainer(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 0 / 1000: 100%|██████████| 3/3 [00:00<00:00,  7.47it/s]\n",
      "epoch 1 / 1000: 100%|██████████| 3/3 [00:00<00:00, 11.93it/s]\n",
      "epoch 2 / 1000: 100%|██████████| 3/3 [00:00<00:00,  8.91it/s]\n",
      "epoch 3 / 1000: 100%|██████████| 3/3 [00:00<00:00, 11.49it/s]\n",
      "epoch 4 / 1000: 100%|██████████| 3/3 [00:00<00:00, 12.22it/s]\n",
      "epoch 5 / 1000: 100%|██████████| 3/3 [00:00<00:00, 11.90it/s]\n",
      "epoch 6 / 1000: 100%|██████████| 3/3 [00:00<00:00, 12.01it/s]\n",
      "epoch 7 / 1000: 100%|██████████| 3/3 [00:00<00:00, 10.07it/s]\n",
      "epoch 8 / 1000: 100%|██████████| 3/3 [00:00<00:00, 12.17it/s]\n",
      "epoch 9 / 1000: 100%|██████████| 3/3 [00:00<00:00, 11.61it/s]\n",
      "epoch 10 / 1000:   0%|          | 0/3 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-16-ebfa0b3e917e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msmall_train_iter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_epochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-9-13041f291b9f>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, train_iter, n_epochs)\u001b[0m\n\u001b[1;32m     34\u001b[0m                 \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 36\u001b[0;31m                 \u001b[0mgc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     37\u001b[0m                 \u001b[0;31m# TODO print statistics from training / validation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mlosses\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ],
     "output_type": "error"
    }
   ],
   "source": [
    "history = trainer.train(small_train_iter, n_epochs=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "first_val_batch = next(iter(small_train_iter))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Variable containing:\n",
       " 64\n",
       " 63\n",
       " 67\n",
       " 69\n",
       " 28\n",
       " 12\n",
       " 81\n",
       "  5\n",
       "  4\n",
       " 21\n",
       "  2\n",
       " 14\n",
       " 57\n",
       " 46\n",
       " 47\n",
       " 65\n",
       " 77\n",
       " 35\n",
       " 43\n",
       " 22\n",
       " 71\n",
       " 24\n",
       " 55\n",
       " 26\n",
       "  6\n",
       " 27\n",
       " 34\n",
       "  1\n",
       " 25\n",
       " 68\n",
       " 48\n",
       "  8\n",
       "[torch.cuda.LongTensor of size 32 (GPU 0)]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "first_val_batch.user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "out = model.forward(first_val_batch.user, first_val_batch.item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "81"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "first_val_batch.batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "batch_predict = out[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "torch.save(batch_predict, 'batch_predict_sample.trch')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('vocab_itos_sample.pkl', 'wb') as f:\n",
    "    pickle.dump(small_text_vocab.itos, f)\n",
    "with open('vocab_stoi_sample.pkl', 'wb') as f:\n",
    "    pickle.dump(small_text_vocab.stoi, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
