{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import random\n",
    "\n",
    "from itertools import chain\n",
    "from torch.autograd import Variable\n",
    "\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "if torch.cuda.is_available():\n",
    "    import torch.cuda as device\n",
    "else:\n",
    "    import torch as device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Merger(nn.Module):\n",
    "    def __init__(self, latent_factors_count, hidden_size):\n",
    "        super(Merger, self).__init__()\n",
    "        self.user_model = nn.Linear(latent_factors_count, hidden_size, bias=False)\n",
    "        self.item_model = nn.Linear(latent_factors_count, hidden_size, bias=False)\n",
    "        self.bias = nn.Parameter(torch.Tensor(1))\n",
    "        \n",
    "    def forward(self, user_embed, item_embed):\n",
    "        return nn.Sigmoid()(self.user_model(user_embed) + self.item_model(item_embed) + self.bias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ContextMerger(nn.Module):\n",
    "    def __init__(self, latent_factors_count, vocabulary_size, context_size):\n",
    "        super(ContextMerger, self).__init__()\n",
    "        self.user_model = nn.Linear(latent_factors_count, context_size, bias=False)\n",
    "        self.item_model = nn.Linear(latent_factors_count, context_size, bias=False)\n",
    "        self.rating_weight = nn.Parameter(torch.Tensor(1))\n",
    "        self.review_model = nn.Linear(vocabulary_size, context_size, bias=False)\n",
    "        self.bias = nn.Parameter(torch.Tensor(1))\n",
    "        \n",
    "    def forward(self, user_embed, item_embed, rating, review):\n",
    "        return nn.Tanh()(\n",
    "            self.user_model(user_embed) + self.item_model(item_embed) + \\\n",
    "            self.rating_weight * rating + self.review_model(review) + self.bias\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderModel(nn.Module):\n",
    "    def __init__(self, users_count, items_count, latent_factors_count, vocabulary_size=333,\n",
    "                 context_size=50, hidden_size=400, n_regression_layers=3, n_review_layers=1):\n",
    "        super(EncoderModel, self).__init__()\n",
    "        self.latent_factors_count = latent_factors_count\n",
    "\n",
    "        self.user_embedding = nn.Embedding(users_count, latent_factors_count)\n",
    "        self.item_embedding = nn.Embedding(items_count, latent_factors_count)\n",
    "        \n",
    "        self.merger = Merger(latent_factors_count, hidden_size)\n",
    "        self.regression_model = nn.Sequential(\n",
    "              *(list(chain.from_iterable([\n",
    "                  [nn.Linear(hidden_size, hidden_size), nn.Sigmoid()]\n",
    "                  for _ in range(n_regression_layers - 1)])) + \\\n",
    "              [nn.Linear(hidden_size, hidden_size), nn.Linear(hidden_size, 1)])\n",
    "        )\n",
    "        self.review_model = nn.Sequential(\n",
    "            *(list(chain.from_iterable([\n",
    "                      [nn.Linear(hidden_size, hidden_size), nn.Sigmoid()]\n",
    "                      for _ in range(n_review_layers - 1)])) + \\\n",
    "                  [nn.Linear(hidden_size, vocabulary_size)])\n",
    "        )\n",
    "        self.context_merger = ContextMerger(latent_factors_count, vocabulary_size, context_size)\n",
    "\n",
    "    def forward(self, input_user, input_item):\n",
    "        embedded_user = self.user_embedding(input_user)\n",
    "        embedded_item = self.item_embedding(input_item)\n",
    "        \n",
    "        merged = self.merger(embedded_user, embedded_item)\n",
    "        regression_result = self.regression_model(merged)\n",
    "        review_result = self.review_model(merged)\n",
    "        review_softmax = nn.Softmax()(review_result)\n",
    "        \n",
    "        context = self.context_merger(embedded_user, embedded_item, regression_result, review_result)\n",
    "        return regression_result, review_softmax, context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = EncoderModel(10, 10, 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "a, b, c = model.forward(Variable(torch.LongTensor([1, 2])),\n",
    "                        Variable(torch.LongTensor([3, 4])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class DecoderModel(nn.Module):\n",
    "    def __init__(self, hidden_size=400, context_size=50, vocabulary_size=333):\n",
    "        super(DecoderModel, self).__init__()\n",
    "        \n",
    "        self.embedding = nn.Embedding(vocabulary_size, context_size)\n",
    "        self.gru = nn.GRU(context_size, context_size)\n",
    "        self.out = nn.Linear(context_size, vocabulary_size)\n",
    "        self.softmax = nn.LogSoftmax()\n",
    "        \n",
    "    def forward(self, input, hidden):\n",
    "        output = self.embedding(input).view(len(input), 1, -1)\n",
    "        hidden = hidden.view(hidden.size()[0], 1, -1)\n",
    "        output, hidden = self.gru(output, hidden)\n",
    "        output = self.softmax(self.out(output))\n",
    "        return output, hidden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "decoder = DecoderModel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "out, hidden = decoder.forward(Variable(torch.LongTensor([1, 2, 1, 1 ,2 , 2])), c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Variable containing:\n",
       "( 0 ,.,.) = \n",
       "  0.1467  0.1619  0.1594  ...   0.1515  0.2121  0.1823\n",
       "\n",
       "( 1 ,.,.) = \n",
       "  0.1800  0.1501  0.1731  ...   0.1638  0.1671  0.1857\n",
       "\n",
       "( 2 ,.,.) = \n",
       "  0.1508  0.1657  0.1679  ...   0.1679  0.1702  0.1560\n",
       "\n",
       "( 3 ,.,.) = \n",
       "  0.1428  0.1812  0.1622  ...   0.1682  0.1747  0.1449\n",
       "\n",
       "( 4 ,.,.) = \n",
       "  0.1803  0.1744  0.1673  ...   0.1721  0.1442  0.1642\n",
       "\n",
       "( 5 ,.,.) = \n",
       "  0.1994  0.1666  0.1701  ...   0.1764  0.1317  0.1670\n",
       "[torch.FloatTensor of size 6x1x333]"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.exp(out)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
