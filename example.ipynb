{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.model import Model\n",
    "from src.trainer import Trainer\n",
    "from src.data_reader import amazon_dataset_iters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading datasets...\n",
      "datasets loaded\n",
      "item vocab built\n",
      "user vocab built\n",
      "text vocab built\n",
      "tips vocab built\n"
     ]
    }
   ],
   "source": [
    "text_vocab, tips_vocab, train_iter, val_iter, test_iter = (\n",
    "    amazon_dataset_iters('./data', device=-1)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/ipykernel_launcher.py:2: DeprecationWarning: generator 'Iterator.__iter__' raised StopIteration\n",
      "  \n",
      "/usr/local/lib/python3.6/site-packages/ipykernel_launcher.py:3: DeprecationWarning: generator 'Iterator.__iter__' raised StopIteration\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "/usr/local/lib/python3.6/site-packages/ipykernel_launcher.py:4: DeprecationWarning: generator 'Iterator.__iter__' raised StopIteration\n",
      "  after removing the cwd from sys.path.\n",
      "/usr/local/lib/python3.6/site-packages/ipykernel_launcher.py:5: DeprecationWarning: generator 'Iterator.__iter__' raised StopIteration\n",
      "  \"\"\"\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "torch.FloatTensor constructor received an invalid combination of arguments - got (numpy.int64, int), but expected one of:\n * no arguments\n * (int ...)\n      didn't match because some of the arguments have invalid types: (\u001b[31;1mnumpy.int64\u001b[0m, \u001b[31;1mint\u001b[0m)\n * (torch.FloatTensor viewed_tensor)\n * (torch.Size size)\n * (torch.FloatStorage data)\n * (Sequence data)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-34-756bbc18ca9c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m                               [i.user.max().data.numpy() for i in test_iter])[0],\n\u001b[1;32m      6\u001b[0m               \u001b[0mcontext_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m               hidden_size=50)\n\u001b[0m",
      "\u001b[0;32m~/Documents/NeuralRatingRegression/src/model.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, users_count, items_count, vocabulary_size, user_latent_factors_count, item_latent_factors_count, context_size, hidden_size, n_regression_layers, n_review_layers, max_tip_len)\u001b[0m\n\u001b[1;32m    133\u001b[0m                                     \u001b[0mhidden_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mhidden_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    134\u001b[0m                                     \u001b[0mn_regression_layers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mn_regression_layers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 135\u001b[0;31m                                     n_review_layers=n_review_layers)\n\u001b[0m\u001b[1;32m    136\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    137\u001b[0m         self.decoder = DecoderModel(context_size=context_size,\n",
      "\u001b[0;32m~/Documents/NeuralRatingRegression/src/model.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, users_count, items_count, user_latent_factors_count, item_latent_factors_count, vocabulary_size, context_size, hidden_size, n_regression_layers, n_review_layers)\u001b[0m\n\u001b[1;32m     55\u001b[0m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mEncoderModel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 57\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muser_embedding\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEmbedding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0musers_count\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muser_latent_factors_count\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     58\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem_embedding\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEmbedding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitems_count\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mitem_latent_factors_count\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/torch/nn/modules/sparse.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, num_embeddings, embedding_dim, padding_idx, max_norm, norm_type, scale_grad_by_freq, sparse)\u001b[0m\n\u001b[1;32m     75\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnorm_type\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnorm_type\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscale_grad_by_freq\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscale_grad_by_freq\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 77\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mParameter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_embeddings\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0membedding_dim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     78\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msparse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msparse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: torch.FloatTensor constructor received an invalid combination of arguments - got (numpy.int64, int), but expected one of:\n * no arguments\n * (int ...)\n      didn't match because some of the arguments have invalid types: (\u001b[31;1mnumpy.int64\u001b[0m, \u001b[31;1mint\u001b[0m)\n * (torch.FloatTensor viewed_tensor)\n * (torch.Size size)\n * (torch.FloatStorage data)\n * (Sequence data)\n"
     ]
    }
   ],
   "source": [
    "model = Model(vocabulary_size=len(text_vocab.itos),\n",
    "              items_count=max([i.item.max().data.numpy() for i in train_iter] +\n",
    "                              [i.item.max().data.numpy() for i in test_iter])[0],\n",
    "              users_count=max([i.user.max().data.numpy() for i in train_iter] +\n",
    "                              [i.user.max().data.numpy() for i in test_iter])[0],\n",
    "              context_size=50,\n",
    "              hidden_size=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Trainer(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
